{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Library\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Define functions for decision tree and random forest\n",
    "\n",
    "def entropy(y):\n",
    "    counter = Counter(y)\n",
    "    entropy = 0\n",
    "    for label in counter:\n",
    "        probability = counter[label] / len(y)\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    return entropy\n",
    "\n",
    "def information_gain(X, y, feature_index, threshold):\n",
    "    left_indices = X[:, feature_index] < threshold\n",
    "    right_indices = ~left_indices\n",
    "    left_entropy = entropy(y[left_indices])\n",
    "    right_entropy = entropy(y[right_indices])\n",
    "    total_entropy = entropy(y)\n",
    "    return total_entropy - (left_entropy * sum(left_indices) / len(y)) - (right_entropy * sum(right_indices) / len(y))\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(set(y))\n",
    "\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_gain = -1\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = sorted(set(X[:, feature_index]))\n",
    "            for threshold in thresholds:\n",
    "                gain = information_gain(X, y, feature_index, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "                    best_gain = gain\n",
    "\n",
    "        left_indices = X[:, best_feature] < best_threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        if sum(left_indices) == 0 or sum(right_indices) == 0:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "        left_tree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return (best_feature, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while isinstance(node, tuple):\n",
    "            feature, threshold, left_subtree, right_subtree = node\n",
    "            if inputs[feature] < threshold:\n",
    "                node = left_subtree\n",
    "            else:\n",
    "                node = right_subtree\n",
    "        return node\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            tree.fit(X[indices], y[indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.trees)), dtype=int)\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X)\n",
    "        return [Counter(row).most_common(1)[0][0] for row in predictions]\n",
    "\n",
    "# Example usage with Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier_custom = RandomForest(n_estimators=100, max_depth=None)\n",
    "rf_classifier_custom.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_custom = rf_classifier_custom.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
    "print(\"Accuracy (Custom Random Forest):\", accuracy_custom)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
