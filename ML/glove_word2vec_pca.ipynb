{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove & Word2Vec with ANN\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained GloVe word vectors\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# Load pre-trained Word2Vec word vectors\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Example sentences and labels\n",
    "sentences = [\n",
    "    \"the cat sat on the mat\",\n",
    "    \"the dog ate my homework\",\n",
    "    \"the sun is shining\"\n",
    "]\n",
    "labels = [0, 1, 0]  # Example labels, binary classification\n",
    "\n",
    "# Function to preprocess sentences using embeddings\n",
    "def preprocess_sentences(sentences, model):\n",
    "    max_length = max(len(sentence.split()) for sentence in sentences)\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        sentence_emb = []\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                sentence_emb.append(model[word])\n",
    "            else:\n",
    "                sentence_emb.append(np.zeros(model.vector_size))  # Use zero vector for out-of-vocabulary words\n",
    "        embeddings.append(sentence_emb)\n",
    "    return np.array(embeddings), max_length\n",
    "\n",
    "# Preprocess sentences using GloVe embeddings\n",
    "glove_embeddings, max_length_glove = preprocess_sentences(sentences, glove_model)\n",
    "\n",
    "# Preprocess sentences using Word2Vec embeddings\n",
    "word2vec_embeddings, max_length_word2vec = preprocess_sentences(sentences, word2vec_model)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "glove_embeddings = pad_sequences(glove_embeddings, maxlen=max_length_glove, padding='post')\n",
    "word2vec_embeddings = pad_sequences(word2vec_embeddings, maxlen=max_length_word2vec, padding='post')\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_glove, X_test_glove, y_train, y_test = train_test_split(glove_embeddings, labels, test_size=0.2, random_state=42)\n",
    "X_train_word2vec, X_test_word2vec, _, _ = train_test_split(word2vec_embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train ANN model with GloVe embeddings\n",
    "model_glove = Sequential([\n",
    "    Embedding(input_dim=len(glove_model.index2word) + 1, output_dim=100, input_length=max_length_glove, weights=[glove_model.vectors], trainable=False),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_glove.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model_glove.fit(X_train_glove, y_train, validation_data=(X_test_glove, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Build and train ANN model with Word2Vec embeddings\n",
    "model_word2vec = Sequential([\n",
    "    Embedding(input_dim=len(word2vec_model.index2word) + 1, output_dim=300, input_length=max_length_word2vec, weights=[word2vec_model.vectors], trainable=False),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_word2vec.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model_word2vec.fit(X_train_word2vec, y_train, validation_data=(X_test_word2vec, y_test), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Glove, Word2Vec, PCA \n",
    "\n",
    "import gensim.downloader as api\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Download pre-trained GloVe word vectors\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# Download pre-trained Word2Vec word vectors\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"dog cat pet\",\n",
    "    \"blue sky\",\n",
    "    \"banana apple fruit\"\n",
    "]\n",
    "\n",
    "# Preprocess sentences using GloVe embeddings\n",
    "def preprocess_glove(sentences, model):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        vector_sum = np.zeros(model.vector_size)\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                vector_sum += model[word]\n",
    "        embeddings.append(vector_sum)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "glove_embeddings = preprocess_glove(sentences, glove_model)\n",
    "print(\"GloVe Embeddings:\")\n",
    "print(glove_embeddings)\n",
    "\n",
    "# Preprocess sentences using Word2Vec embeddings\n",
    "def preprocess_word2vec(sentences, model):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        vector_sum = np.zeros(model.vector_size)\n",
    "        for word in words:\n",
    "            if word in model:\n",
    "                vector_sum += model[word]\n",
    "        embeddings.append(vector_sum)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "word2vec_embeddings = preprocess_word2vec(sentences, word2vec_model)\n",
    "print(\"\\nWord2Vec Embeddings:\")\n",
    "print(word2vec_embeddings)\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "def apply_pca(embeddings, n_components=2):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(embeddings)\n",
    "    return pca_result\n",
    "\n",
    "# Apply PCA on GloVe embeddings\n",
    "glove_pca_result = apply_pca(glove_embeddings)\n",
    "print(\"\\nPCA Result for GloVe Embeddings:\")\n",
    "print(glove_pca_result)\n",
    "\n",
    "# Apply PCA on Word2Vec embeddings\n",
    "word2vec_pca_result = apply_pca(word2vec_embeddings)\n",
    "print(\"\\nPCA Result for Word2Vec Embeddings:\")\n",
    "print(word2vec_pca_result)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
