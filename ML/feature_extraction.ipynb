{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Library\n",
    "# One-Hot Encoding\n",
    "def one_hot_encoding(data):\n",
    "    unique_values = list(set(data))\n",
    "    encoding = []\n",
    "    for val in data:\n",
    "        encoding.append([1 if val == u else 0 for u in unique_values])\n",
    "    return encoding\n",
    "\n",
    "# Count Vectorizer\n",
    "def count_vectorizer(data):\n",
    "    unique_words = list(set(data))\n",
    "    vectors = []\n",
    "    for sentence in data:\n",
    "        vector = [0] * len(unique_words)\n",
    "        for word in sentence.split():\n",
    "            if word in unique_words:\n",
    "                vector[unique_words.index(word)] += 1\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "def tf_idf(data):\n",
    "    unique_words = list(set([word for sentence in data for word in sentence.split()]))\n",
    "    idf = {}\n",
    "    for word in unique_words:\n",
    "        doc_count = sum(1 for sentence in data if word in sentence)\n",
    "        idf[word] = np.log(len(data) / (1 + doc_count))\n",
    "    \n",
    "    tfidf_matrix = []\n",
    "    for sentence in data:\n",
    "        tfidf_vector = []\n",
    "        for word in unique_words:\n",
    "            tf = sentence.split().count(word) / len(sentence.split())\n",
    "            tfidf_vector.append(tf * idf[word])\n",
    "        tfidf_matrix.append(tfidf_vector)\n",
    "    return tfidf_matrix\n",
    "\n",
    "# Example usage\n",
    "data = [\"hello world\", \"hello\", \"world\", \"hello again\"]\n",
    "print(\"Original Data:\", data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "one_hot_encoded = one_hot_encoding(data)\n",
    "print(\"\\nOne-Hot Encoded:\")\n",
    "for sentence in one_hot_encoded:\n",
    "    print(sentence)\n",
    "\n",
    "# Count Vectorizer\n",
    "count_vectors = count_vectorizer(data)\n",
    "print(\"\\nCount Vectors:\")\n",
    "for vector in count_vectors:\n",
    "    print(vector)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_matrix = tf_idf(data)\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "for vector in tfidf_matrix:\n",
    "    print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Library\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Example data\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "# One-hot encoding\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "one_hot_encoded = vectorizer.fit_transform(documents)\n",
    "print(\"One-Hot Encoded Features:\")\n",
    "print(one_hot_encoded.toarray())\n",
    "print(\"Vocabulary:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Count Vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorized = count_vectorizer.fit_transform(documents)\n",
    "print(\"\\nCount Vectorized Features:\")\n",
    "print(count_vectorized.toarray())\n",
    "print(\"Vocabulary:\")\n",
    "print(count_vectorizer.get_feature_names_out())\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorized = tfidf_vectorizer.fit_transform(documents)\n",
    "print(\"\\nTF-IDF Vectorized Features:\")\n",
    "print(tfidf_vectorized.toarray())\n",
    "print(\"Vocabulary:\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
